# Chapter Two Exercises

This document is rendered in R.

```
> rmarkdown::render('two.Rmd', output_format="pdf_document")
```

## 2.1

First, type in the data as $x$.

```
> x <- c(19, 18.7, 19.3, 19.2, 18.9, 19, 20.2, 19.9, 18.6, 19.4, 19.3, 18.8, 19.3, 19.2, 18.7, 18.5, 18.6, 19.7, 19.9, 20, 19.5, 19.4, 19.6, 20, 18.9)
```

Calculate the mean manually (somewhat manually), and verify it using
the base R function.

```
> sum(x)
[1] 481.6
> length(x)
[1] 25
> sum(x) / length(x)
[1] 19.264
> mean(x)
[1] 19.264
```

Now calculate the standard deviation and verify with R base *sd*,
which uses Barlow's equation 2.11, with $N-1$ on the denominator.

```
> (x - mean(x))^2
 [1] 0.069696 0.318096 0.001296 0.004096 0.132496 0.069696 0.876096 0.404496
 [9] 0.440896 0.018496 0.001296 0.215296 0.001296 0.004096 0.318096 0.583696
[17] 0.440896 0.190096 0.404496 0.541696 0.055696 0.018496 0.112896 0.541696
[25] 0.132496
> sum((x - mean(x))^2)
[1] 5.8976
> sqrt(sum((x - mean(x))^2)/(length(x)-1))
[1] 0.495715
> sd(x)
[1] 0.495715
```

## 2.2

Now add in the instructor's age of 37 to see how that affects the mean
and standard deviation.

```
> mean(c(x, 37))
[1] 19.94615
> sd(c(x, 37))
[1] 3.512063
>
```

## 2.3

Below I create a function for the skew.

```
> skew <- function(x) { sum((x - mean(x))^3)/(length(x)*sd(x)^3) }
> skew(x)
[1] 0.2124908
> skew(c(x, 37))
[1] 4.386403
> 
```

For verifying that, I searched for calculation of skew in R and found
a blog about using the "moments" package.

http://www.r-bloggers.com/measures-of-skewness-and-kurtosis/

```
> library(moments)
> skewness(x)
[1] 0.2259089
> skew(x)
[1] 0.2124908
```

They're a bit different.  Subtracting one in the denominator isn't
quite enough to make them the same.

```
> skew2 <- function(x) { sum((x - mean(x))^3)/((length(x)-1)*sd(x)^3) }
> skew2(x)
[1] 0.2213446
> 
```

Looking at the code (shown below), I see that the *moments::skewness*
doesn't subtract one from the denominator in the standard deviation
calculation.

```
> skewness
function (x, na.rm = FALSE) 
{
    if (is.matrix(x)) 
        apply(x, 2, skewness, na.rm = na.rm)
    else if (is.vector(x)) {
        if (na.rm) 
            x <- x[!is.na(x)]
        n <- length(x)
        (sum((x - mean(x))^3)/n)/(sum((x - mean(x))^2)/n)^(3/2)
    }
    else if (is.data.frame(x)) 
        sapply(x, skewness, na.rm = na.rm)
    else skewness(as.vector(x), na.rm = na.rm)
}
<environment: namespace:moments>
> 
```

## 2.4

The following contents are in file `grades.dat`.

```
classical quantum
22	  63
48	  39
76	  61
10	  30
22	  51
4	  44
68	  74
44	  78
10	  55
76	  58
14	  41
56	  69
```

The grades are loaded.

```
> df <- data.frame(read.table("grades.dat", header=T))
```

The dplyr library can do aggregations, and I want to get the hang of
it.  I also want to make that data "tidy", so I install *tidyr*.

```
> library(dplyr)
> install.packages("tidyr")
> library(tidyr)
```

I want the "classical" or "quantum" course specification to be a
categorical column in the data, and *gather* from *tidyr* does that.

```
> df %>% gather(course, grade, classical:quantum)
      course grade
1  classical    22
2  classical    48
3  classical    76
4  classical    10
5  classical    22
6  classical     4
7  classical    68
8  classical    44
9  classical    10
10 classical    76
11 classical    14
12 classical    56
13   quantum    63
14   quantum    39
15   quantum    61
16   quantum    30
17   quantum    51
18   quantum    44
19   quantum    74
20   quantum    78
21   quantum    55
22   quantum    58
23   quantum    41
24   quantum    69
> 
```

Then I can group by course and do summary statistics using
*dplyr::summarize*.

```
> df %>% gather(course, grade, classical:quantum) %>%
+  group_by(course) %>% summarize(mean=mean(grade))
Source: local data frame [2 x 2]

     course  mean
      (chr) (dbl)
1 classical 37.50
2   quantum 55.25
> 
```

But I cannot think of a fancy way to do the covariance.

```
> cov(df$classical, df$quantum)
[1] 226.3182
> 
```

By hand, Barlow's equation 2.19c is implemented below.

```
> mean(x*y) - (mean(x)*mean(y))
[1] 207.4583
> 
```

It's different from the results of `cov`, probably because of the
`method` parameter used by default.

```
> cov(x, y, method="kendall")
[1] 46
> cov(x, y, method="pearson")
[1] 226.3182
> cov(x, y, method="spearman")
[1] 6.909091
> 
```

I guess not.

Here's the correlation by Barlow's 2.20b, checked with the base R
correlation function.

```
> (mean(x*y) - (mean(x)*mean(y))) / (sd(x)*sd(y))
[1] 0.5180672
> cor(x, y)
[1] 0.5651642
> 
```

## 2.6

I lost patience after entering three fifths of the data.  Then I tried
an old-fashioned stem and leaf plot to get a quick feel for the way
the histogram will look.

```
> eighty <- read.table("80.dat")
> eighty
  V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
1 90 90 79 84 78 91 88 90 85  80
2 88 75 73 79 78 79 67 83 68  60
3 73 79 69 74 76 68 72 72 75  60
> stem(c(t(eighty)))

  The decimal point is 1 digit(s) to the right of the |

  6 | 00
  6 | 7889
  7 | 22334
  7 | 556889999
  8 | 034
  8 | 588
  9 | 0001

> 
```

Use histogram in ggplot now.

```
> eighty <- c(t(eighty))
> library(ggplot2)
> qplot(eighty, binwidth=5)
> pdf("hist.pdf")
> 
```

![](hist.pdf)